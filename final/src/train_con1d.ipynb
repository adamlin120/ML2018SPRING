{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to True to replicate the result\n",
    "COMPLETE_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/adam/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n",
    "                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, config, data_dir, list_IDs, labels=None, \n",
    "                 batch_size=64, preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        X = np.empty((cur_batch_size, *self.dim))\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n",
    "                                        res_type='kaiser_fast')\n",
    "\n",
    "            # Random offset / Padding\n",
    "            if len(data) > input_length:\n",
    "                max_offset = len(data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                data = data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(data):\n",
    "                    max_offset = input_length - len(data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "                \n",
    "            # Normalization + Other Preprocessing\n",
    "            if self.config.use_mfcc:\n",
    "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n",
    "                                                   n_mfcc=self.config.n_mfcc)\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "            else:\n",
    "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = GlobalMaxPool1D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def get_1d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adam/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Fold:  0\n",
      "##################################################\n",
      "WARNING:tensorflow:From /home/adam/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 132s 988ms/step - loss: 3.3858 - acc: 0.0757 - val_loss: 3.0850 - val_acc: 0.1372\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08498, saving model to best_0.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 109s 814ms/step - loss: 2.9589 - acc: 0.1558 - val_loss: 2.8919 - val_acc: 0.1937\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08498 to 2.89189, saving model to best_0.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 2.7148 - acc: 0.2230 - val_loss: 2.5551 - val_acc: 0.2785\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.89189 to 2.55508, saving model to best_0.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 94s 704ms/step - loss: 2.4996 - acc: 0.2761 - val_loss: 2.4010 - val_acc: 0.3173\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.55508 to 2.40100, saving model to best_0.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 90s 675ms/step - loss: 2.3584 - acc: 0.3130 - val_loss: 2.2632 - val_acc: 0.3424\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.40100 to 2.26315, saving model to best_0.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 2.2586 - acc: 0.3433 - val_loss: 2.3821 - val_acc: 0.3047\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.26315\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 2.1802 - acc: 0.3690 - val_loss: 2.0887 - val_acc: 0.3958\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.26315 to 2.08872, saving model to best_0.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 2.1078 - acc: 0.3855 - val_loss: 2.1880 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.08872\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 2.0506 - acc: 0.4075 - val_loss: 2.0463 - val_acc: 0.4073\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.08872 to 2.04632, saving model to best_0.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 2.0018 - acc: 0.4152 - val_loss: 1.9972 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.04632 to 1.99715, saving model to best_0.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.9193 - acc: 0.4403 - val_loss: 1.9706 - val_acc: 0.4209\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.99715 to 1.97059, saving model to best_0.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 89s 661ms/step - loss: 1.8879 - acc: 0.4417 - val_loss: 1.9014 - val_acc: 0.4607\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.97059 to 1.90143, saving model to best_0.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.8419 - acc: 0.4624 - val_loss: 1.8504 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.90143 to 1.85045, saving model to best_0.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.7767 - acc: 0.4776 - val_loss: 1.9032 - val_acc: 0.4461\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.85045\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.7188 - acc: 0.4977 - val_loss: 1.7780 - val_acc: 0.4827\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.85045 to 1.77799, saving model to best_0.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.6787 - acc: 0.5144 - val_loss: 1.7899 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.77799\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 89s 661ms/step - loss: 1.6423 - acc: 0.5250 - val_loss: 1.8036 - val_acc: 0.4743\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.77799\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.6069 - acc: 0.5283 - val_loss: 1.6957 - val_acc: 0.5016\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.77799 to 1.69565, saving model to best_0.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.5992 - acc: 0.5301 - val_loss: 1.6665 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.69565 to 1.66654, saving model to best_0.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.5396 - acc: 0.5479 - val_loss: 1.6245 - val_acc: 0.5414\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.66654 to 1.62452, saving model to best_0.h5\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.5403 - acc: 0.5500 - val_loss: 1.6392 - val_acc: 0.5257\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.62452\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.4802 - acc: 0.5592 - val_loss: 1.5698 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.62452 to 1.56980, saving model to best_0.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.4999 - acc: 0.5580 - val_loss: 1.6726 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.56980\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.4568 - acc: 0.5733 - val_loss: 1.5089 - val_acc: 0.5592\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.56980 to 1.50890, saving model to best_0.h5\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.4435 - acc: 0.5738 - val_loss: 1.5278 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.50890\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.4061 - acc: 0.5815 - val_loss: 1.6444 - val_acc: 0.5372\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.50890\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.3777 - acc: 0.5796 - val_loss: 1.5340 - val_acc: 0.5759\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.50890\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.3583 - acc: 0.5931 - val_loss: 1.5699 - val_acc: 0.5414\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.50890\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.3355 - acc: 0.6047 - val_loss: 1.5086 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.50890 to 1.50859, saving model to best_0.h5\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.3434 - acc: 0.5958 - val_loss: 1.6090 - val_acc: 0.5571\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.50859\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.3276 - acc: 0.6033 - val_loss: 1.4672 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.50859 to 1.46723, saving model to best_0.h5\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.3172 - acc: 0.6105 - val_loss: 1.5856 - val_acc: 0.5654\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.46723\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.2861 - acc: 0.6144 - val_loss: 1.4718 - val_acc: 0.5853\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.46723\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.2927 - acc: 0.6185 - val_loss: 1.4824 - val_acc: 0.5707\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.46723\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.2544 - acc: 0.6222 - val_loss: 1.5028 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.46723\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 90s 670ms/step - loss: 1.2463 - acc: 0.6264 - val_loss: 1.5492 - val_acc: 0.5508\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.46723\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.1979 - acc: 0.6395 - val_loss: 1.4297 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.46723 to 1.42972, saving model to best_0.h5\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1522 - acc: 0.6587 - val_loss: 1.5074 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.42972\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.1527 - acc: 0.6489 - val_loss: 1.4828 - val_acc: 0.5853\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.42972\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 89s 661ms/step - loss: 1.1294 - acc: 0.6514 - val_loss: 1.4763 - val_acc: 0.5895\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.42972\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.1362 - acc: 0.6535 - val_loss: 1.5331 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.42972\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.1216 - acc: 0.6661 - val_loss: 1.4868 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.42972\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0770 - acc: 0.6680 - val_loss: 1.5226 - val_acc: 0.5738\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.42972\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.0528 - acc: 0.6831 - val_loss: 1.4796 - val_acc: 0.5874\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.42972\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.0460 - acc: 0.6829 - val_loss: 1.5025 - val_acc: 0.5749\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.42972\n",
      "Fold:  1\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 115s 861ms/step - loss: 3.4120 - acc: 0.0676 - val_loss: 3.1357 - val_acc: 0.1144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.13572, saving model to best_1.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 95s 706ms/step - loss: 3.0247 - acc: 0.1434 - val_loss: 2.9019 - val_acc: 0.1668\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.13572 to 2.90193, saving model to best_1.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 96s 716ms/step - loss: 2.7872 - acc: 0.2032 - val_loss: 2.6787 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.90193 to 2.67873, saving model to best_1.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 99s 739ms/step - loss: 2.5416 - acc: 0.2722 - val_loss: 2.5453 - val_acc: 0.2655\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.67873 to 2.54532, saving model to best_1.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 92s 683ms/step - loss: 2.4002 - acc: 0.3101 - val_loss: 2.5011 - val_acc: 0.2812\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.54532 to 2.50106, saving model to best_1.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 93s 691ms/step - loss: 2.2590 - acc: 0.3463 - val_loss: 2.2387 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.50106 to 2.23868, saving model to best_1.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 97s 726ms/step - loss: 2.1555 - acc: 0.3798 - val_loss: 2.2397 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.23868\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 92s 689ms/step - loss: 2.0870 - acc: 0.3910 - val_loss: 2.1354 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.23868 to 2.13544, saving model to best_1.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 1.9889 - acc: 0.4150 - val_loss: 2.0642 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.13544 to 2.06421, saving model to best_1.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.9580 - acc: 0.4314 - val_loss: 1.9709 - val_acc: 0.4428\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.06421 to 1.97090, saving model to best_1.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.8875 - acc: 0.4566 - val_loss: 1.9563 - val_acc: 0.4502\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.97090 to 1.95625, saving model to best_1.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.8489 - acc: 0.4567 - val_loss: 1.9429 - val_acc: 0.4544\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.95625 to 1.94291, saving model to best_1.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.7847 - acc: 0.4808 - val_loss: 1.8504 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.94291 to 1.85039, saving model to best_1.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.7551 - acc: 0.4887 - val_loss: 1.8454 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.85039 to 1.84539, saving model to best_1.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.6868 - acc: 0.5106 - val_loss: 1.7553 - val_acc: 0.5058\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.84539 to 1.75526, saving model to best_1.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.6800 - acc: 0.5099 - val_loss: 1.7434 - val_acc: 0.5236\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.75526 to 1.74341, saving model to best_1.h5\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.6340 - acc: 0.5220 - val_loss: 1.8010 - val_acc: 0.4816\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.74341\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.6073 - acc: 0.5296 - val_loss: 1.7015 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.74341 to 1.70150, saving model to best_1.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.5689 - acc: 0.5363 - val_loss: 1.6904 - val_acc: 0.5257\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.70150 to 1.69043, saving model to best_1.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.5398 - acc: 0.5467 - val_loss: 1.7128 - val_acc: 0.5226\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.69043\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.5187 - acc: 0.5542 - val_loss: 1.6674 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.69043 to 1.66744, saving model to best_1.h5\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.4938 - acc: 0.5529 - val_loss: 1.6316 - val_acc: 0.5498\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.66744 to 1.63155, saving model to best_1.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.4519 - acc: 0.5670 - val_loss: 1.6642 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.63155\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.4521 - acc: 0.5753 - val_loss: 1.6632 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.63155\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.4501 - acc: 0.5769 - val_loss: 1.7335 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.63155\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 89s 664ms/step - loss: 1.4164 - acc: 0.5788 - val_loss: 1.5945 - val_acc: 0.5362\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.63155 to 1.59445, saving model to best_1.h5\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.3908 - acc: 0.5877 - val_loss: 1.5639 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.59445 to 1.56391, saving model to best_1.h5\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.3778 - acc: 0.5899 - val_loss: 1.6087 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.56391\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 89s 662ms/step - loss: 1.3558 - acc: 0.5911 - val_loss: 1.6342 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.56391\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.3245 - acc: 0.6126 - val_loss: 1.5589 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.56391 to 1.55889, saving model to best_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.3164 - acc: 0.6096 - val_loss: 1.5759 - val_acc: 0.5719\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.55889\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.3013 - acc: 0.6137 - val_loss: 1.5932 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.55889\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.3028 - acc: 0.6098 - val_loss: 1.5644 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.55889\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.2864 - acc: 0.6173 - val_loss: 1.5359 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.55889 to 1.53586, saving model to best_1.h5\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 89s 665ms/step - loss: 1.2523 - acc: 0.6224 - val_loss: 1.4841 - val_acc: 0.5992\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.53586 to 1.48413, saving model to best_1.h5\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.2291 - acc: 0.6245 - val_loss: 1.4989 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.48413\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.2371 - acc: 0.6279 - val_loss: 1.5095 - val_acc: 0.5719\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.48413\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 90s 671ms/step - loss: 1.2052 - acc: 0.6342 - val_loss: 1.4874 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.48413\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.2369 - acc: 0.6330 - val_loss: 1.5252 - val_acc: 0.5824\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.48413\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 89s 664ms/step - loss: 1.2006 - acc: 0.6407 - val_loss: 1.5136 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.48413\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.1332 - acc: 0.6587 - val_loss: 1.4718 - val_acc: 0.5782\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.48413 to 1.47177, saving model to best_1.h5\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.1320 - acc: 0.6571 - val_loss: 1.4183 - val_acc: 0.5939\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.47177 to 1.41831, saving model to best_1.h5\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.1160 - acc: 0.6628 - val_loss: 1.5019 - val_acc: 0.5855\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.41831\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 86s 640ms/step - loss: 1.1289 - acc: 0.6616 - val_loss: 1.4605 - val_acc: 0.5887\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.41831\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.0994 - acc: 0.6643 - val_loss: 1.4291 - val_acc: 0.6128\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.41831\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.0828 - acc: 0.6766 - val_loss: 1.5138 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.41831\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 89s 667ms/step - loss: 1.0702 - acc: 0.6723 - val_loss: 1.4651 - val_acc: 0.5992\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.41831\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.0415 - acc: 0.6852 - val_loss: 1.4733 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.41831\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.0061 - acc: 0.6936 - val_loss: 1.4599 - val_acc: 0.5908\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.41831\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.0113 - acc: 0.6944 - val_loss: 1.4458 - val_acc: 0.5992\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.41831\n",
      "Fold:  2\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 109s 816ms/step - loss: 3.4162 - acc: 0.0721 - val_loss: 3.0566 - val_acc: 0.1376\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.05660, saving model to best_2.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 2.9420 - acc: 0.1612 - val_loss: 2.8632 - val_acc: 0.1870\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.05660 to 2.86319, saving model to best_2.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 2.7592 - acc: 0.2154 - val_loss: 2.7700 - val_acc: 0.2027\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.86319 to 2.77001, saving model to best_2.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 2.5873 - acc: 0.2637 - val_loss: 2.7116 - val_acc: 0.2290\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.77001 to 2.71157, saving model to best_2.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 2.4373 - acc: 0.3012 - val_loss: 2.3536 - val_acc: 0.3246\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.71157 to 2.35362, saving model to best_2.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 2.3094 - acc: 0.3318 - val_loss: 2.3195 - val_acc: 0.3319\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.35362 to 2.31952, saving model to best_2.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 2.2370 - acc: 0.3530 - val_loss: 2.2074 - val_acc: 0.3445\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.31952 to 2.20743, saving model to best_2.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 2.1578 - acc: 0.3735 - val_loss: 2.1283 - val_acc: 0.3897\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.20743 to 2.12825, saving model to best_2.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 2.1105 - acc: 0.3845 - val_loss: 2.0380 - val_acc: 0.4076\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.12825 to 2.03801, saving model to best_2.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 2.0337 - acc: 0.4049 - val_loss: 1.9995 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.03801 to 1.99947, saving model to best_2.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.9617 - acc: 0.4216 - val_loss: 2.0030 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.99947\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 91s 677ms/step - loss: 1.9035 - acc: 0.4428 - val_loss: 1.9320 - val_acc: 0.4454\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.99947 to 1.93199, saving model to best_2.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.8593 - acc: 0.4603 - val_loss: 1.8598 - val_acc: 0.4580\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.93199 to 1.85979, saving model to best_2.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.8211 - acc: 0.4676 - val_loss: 1.8330 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.85979 to 1.83295, saving model to best_2.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.7647 - acc: 0.4834 - val_loss: 1.7132 - val_acc: 0.5105\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.83295 to 1.71321, saving model to best_2.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 89s 666ms/step - loss: 1.7161 - acc: 0.4893 - val_loss: 1.7636 - val_acc: 0.4916\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.71321\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.6467 - acc: 0.5179 - val_loss: 1.7449 - val_acc: 0.5053\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.71321\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.6572 - acc: 0.5104 - val_loss: 1.6732 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.71321 to 1.67322, saving model to best_2.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.5941 - acc: 0.5335 - val_loss: 1.6754 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.67322\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.5773 - acc: 0.5362 - val_loss: 1.6901 - val_acc: 0.5210\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.67322\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.5469 - acc: 0.5439 - val_loss: 1.6363 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.67322 to 1.63635, saving model to best_2.h5\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.5121 - acc: 0.5564 - val_loss: 1.6570 - val_acc: 0.5284\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.63635\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.4841 - acc: 0.5685 - val_loss: 1.6480 - val_acc: 0.5294\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.63635\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 89s 662ms/step - loss: 1.4644 - acc: 0.5655 - val_loss: 1.5737 - val_acc: 0.5536\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.63635 to 1.57371, saving model to best_2.h5\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.4334 - acc: 0.5719 - val_loss: 1.5612 - val_acc: 0.5389\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.57371 to 1.56118, saving model to best_2.h5\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.4322 - acc: 0.5776 - val_loss: 1.6268 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.56118\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.4118 - acc: 0.5793 - val_loss: 1.5211 - val_acc: 0.5788\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.56118 to 1.52111, saving model to best_2.h5\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.3921 - acc: 0.5847 - val_loss: 1.4617 - val_acc: 0.5777\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.52111 to 1.46166, saving model to best_2.h5\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.3847 - acc: 0.5915 - val_loss: 1.4825 - val_acc: 0.5746\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.46166\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 86s 646ms/step - loss: 1.3344 - acc: 0.6048 - val_loss: 1.5252 - val_acc: 0.5746\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.46166\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.3350 - acc: 0.6029 - val_loss: 1.4606 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.46166 to 1.46065, saving model to best_2.h5\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.3136 - acc: 0.6139 - val_loss: 1.4693 - val_acc: 0.5914\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.46065\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.3103 - acc: 0.6042 - val_loss: 1.5123 - val_acc: 0.5777\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.46065\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.2871 - acc: 0.6149 - val_loss: 1.4484 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.46065 to 1.44837, saving model to best_2.h5\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.2849 - acc: 0.6129 - val_loss: 1.5161 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.44837\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.2548 - acc: 0.6247 - val_loss: 1.4326 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.44837 to 1.43255, saving model to best_2.h5\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.2458 - acc: 0.6324 - val_loss: 1.4689 - val_acc: 0.5798\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.43255\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 1.2187 - acc: 0.6310 - val_loss: 1.4253 - val_acc: 0.5966\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.43255 to 1.42530, saving model to best_2.h5\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.2187 - acc: 0.6349 - val_loss: 1.3628 - val_acc: 0.6145\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.42530 to 1.36278, saving model to best_2.h5\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.2115 - acc: 0.6376 - val_loss: 1.4490 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.36278\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1891 - acc: 0.6434 - val_loss: 1.4120 - val_acc: 0.5998\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.36278\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 1.1921 - acc: 0.6395 - val_loss: 1.4613 - val_acc: 0.5903\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.36278\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.1849 - acc: 0.6446 - val_loss: 1.3785 - val_acc: 0.6050\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.36278\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.1672 - acc: 0.6518 - val_loss: 1.4177 - val_acc: 0.5956\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.36278\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.1087 - acc: 0.6639 - val_loss: 1.3695 - val_acc: 0.5987\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.36278\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.1089 - acc: 0.6547 - val_loss: 1.3613 - val_acc: 0.6050\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.36278 to 1.36130, saving model to best_2.h5\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0819 - acc: 0.6742 - val_loss: 1.3655 - val_acc: 0.6239\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.36130\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0735 - acc: 0.6768 - val_loss: 1.3971 - val_acc: 0.6113\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.36130\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.0796 - acc: 0.6676 - val_loss: 1.3489 - val_acc: 0.6239\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.36130 to 1.34892, saving model to best_2.h5\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.0670 - acc: 0.6742 - val_loss: 1.3676 - val_acc: 0.6134\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.34892\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.0380 - acc: 0.6800 - val_loss: 1.3385 - val_acc: 0.6218\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.34892 to 1.33845, saving model to best_2.h5\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0529 - acc: 0.6784 - val_loss: 1.3536 - val_acc: 0.6271\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.33845\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 1.0215 - acc: 0.6842 - val_loss: 1.3663 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.33845\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 1.0385 - acc: 0.6779 - val_loss: 1.3998 - val_acc: 0.6208\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.33845\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.0216 - acc: 0.6895 - val_loss: 1.3468 - val_acc: 0.6324\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.33845\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.0208 - acc: 0.6886 - val_loss: 1.2911 - val_acc: 0.6534\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.33845 to 1.29111, saving model to best_2.h5\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.0005 - acc: 0.6953 - val_loss: 1.3864 - val_acc: 0.6092\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.29111\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 0.9999 - acc: 0.7003 - val_loss: 1.3410 - val_acc: 0.6271\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.29111\n",
      "Epoch 59/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.9902 - acc: 0.6977 - val_loss: 1.3265 - val_acc: 0.6145\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.29111\n",
      "Epoch 60/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 0.9932 - acc: 0.6967 - val_loss: 1.3760 - val_acc: 0.6271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_loss did not improve from 1.29111\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 0.9909 - acc: 0.6955 - val_loss: 1.3734 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.29111\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 62/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 0.9508 - acc: 0.7026 - val_loss: 1.3322 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.29111\n",
      "Epoch 63/500\n",
      "134/134 [==============================] - 89s 661ms/step - loss: 0.9328 - acc: 0.7139 - val_loss: 1.2861 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.29111 to 1.28613, saving model to best_2.h5\n",
      "Epoch 64/500\n",
      "134/134 [==============================] - 85s 636ms/step - loss: 0.9075 - acc: 0.7199 - val_loss: 1.2850 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.28613 to 1.28496, saving model to best_2.h5\n",
      "Epoch 65/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.8993 - acc: 0.7220 - val_loss: 1.3241 - val_acc: 0.6376\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.28496\n",
      "Epoch 66/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 0.9217 - acc: 0.7219 - val_loss: 1.3598 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.28496\n",
      "Epoch 67/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 0.9107 - acc: 0.7186 - val_loss: 1.3173 - val_acc: 0.6292\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.28496\n",
      "Epoch 68/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 0.8993 - acc: 0.7218 - val_loss: 1.3686 - val_acc: 0.6345\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.28496\n",
      "Epoch 69/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 0.8870 - acc: 0.7233 - val_loss: 1.3352 - val_acc: 0.6387\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.28496\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 70/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 0.8734 - acc: 0.7310 - val_loss: 1.3384 - val_acc: 0.6313\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.28496\n",
      "Epoch 71/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 0.8477 - acc: 0.7404 - val_loss: 1.3001 - val_acc: 0.6544\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.28496\n",
      "Epoch 72/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 0.8402 - acc: 0.7430 - val_loss: 1.3411 - val_acc: 0.6261\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.28496\n",
      "Fold:  3\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 109s 814ms/step - loss: 3.3987 - acc: 0.0709 - val_loss: 3.0833 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.08334, saving model to best_3.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 2.9482 - acc: 0.1588 - val_loss: 2.8241 - val_acc: 0.1977\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.08334 to 2.82405, saving model to best_3.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 2.7670 - acc: 0.2117 - val_loss: 2.7618 - val_acc: 0.2219\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82405 to 2.76179, saving model to best_3.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 2.5907 - acc: 0.2644 - val_loss: 2.4861 - val_acc: 0.2997\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.76179 to 2.48611, saving model to best_3.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 2.4144 - acc: 0.3149 - val_loss: 2.3422 - val_acc: 0.3239\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.48611 to 2.34223, saving model to best_3.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 2.2902 - acc: 0.3400 - val_loss: 2.3647 - val_acc: 0.3270\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.34223\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 2.1979 - acc: 0.3654 - val_loss: 2.1623 - val_acc: 0.3785\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.34223 to 2.16230, saving model to best_3.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 2.1079 - acc: 0.3934 - val_loss: 2.1021 - val_acc: 0.4143\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.16230 to 2.10210, saving model to best_3.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 2.0242 - acc: 0.4140 - val_loss: 2.0600 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.10210 to 2.06004, saving model to best_3.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.9563 - acc: 0.4317 - val_loss: 2.0016 - val_acc: 0.4311\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.06004 to 2.00161, saving model to best_3.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.9207 - acc: 0.4379 - val_loss: 2.0709 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.00161\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.8281 - acc: 0.4687 - val_loss: 1.8839 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.00161 to 1.88388, saving model to best_3.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 1.7751 - acc: 0.4795 - val_loss: 1.8801 - val_acc: 0.4679\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.88388 to 1.88008, saving model to best_3.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.7133 - acc: 0.4962 - val_loss: 1.8475 - val_acc: 0.4795\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.88008 to 1.84752, saving model to best_3.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.6848 - acc: 0.5047 - val_loss: 1.8504 - val_acc: 0.4858\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.84752\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 90s 669ms/step - loss: 1.6512 - acc: 0.5203 - val_loss: 1.7564 - val_acc: 0.5026\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.84752 to 1.75644, saving model to best_3.h5\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.6090 - acc: 0.5296 - val_loss: 1.8154 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.75644\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 89s 661ms/step - loss: 1.5824 - acc: 0.5328 - val_loss: 1.7248 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.75644 to 1.72477, saving model to best_3.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.5473 - acc: 0.5444 - val_loss: 1.7130 - val_acc: 0.5131\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.72477 to 1.71295, saving model to best_3.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.5198 - acc: 0.5506 - val_loss: 1.6484 - val_acc: 0.5415\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.71295 to 1.64841, saving model to best_3.h5\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.4936 - acc: 0.5563 - val_loss: 1.7345 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.64841\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.4791 - acc: 0.5610 - val_loss: 1.6227 - val_acc: 0.5426\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.64841 to 1.62268, saving model to best_3.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.4353 - acc: 0.5763 - val_loss: 1.6590 - val_acc: 0.5331\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.62268\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 1.4305 - acc: 0.5753 - val_loss: 1.6917 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.62268\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.4113 - acc: 0.5814 - val_loss: 1.6484 - val_acc: 0.5363\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.62268\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.3576 - acc: 0.5970 - val_loss: 1.6370 - val_acc: 0.5468\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.62268\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.3636 - acc: 0.5948 - val_loss: 1.5658 - val_acc: 0.5699\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.62268 to 1.56580, saving model to best_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.3613 - acc: 0.5941 - val_loss: 1.5537 - val_acc: 0.5668\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.56580 to 1.55372, saving model to best_3.h5\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.3284 - acc: 0.6002 - val_loss: 1.6140 - val_acc: 0.5584\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.55372\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.3123 - acc: 0.6093 - val_loss: 1.5733 - val_acc: 0.5731\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.55372\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 1.2976 - acc: 0.6145 - val_loss: 1.5993 - val_acc: 0.5678\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.55372\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.2866 - acc: 0.6157 - val_loss: 1.5597 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.55372\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.2671 - acc: 0.6239 - val_loss: 1.5804 - val_acc: 0.5605\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.55372\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.2008 - acc: 0.6430 - val_loss: 1.5657 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.55372\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1645 - acc: 0.6497 - val_loss: 1.5505 - val_acc: 0.5868\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.55372 to 1.55050, saving model to best_3.h5\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.1656 - acc: 0.6478 - val_loss: 1.5105 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.55050 to 1.51046, saving model to best_3.h5\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.1438 - acc: 0.6553 - val_loss: 1.5268 - val_acc: 0.5846\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.51046\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.1396 - acc: 0.6617 - val_loss: 1.4343 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.51046 to 1.43432, saving model to best_3.h5\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.1266 - acc: 0.6627 - val_loss: 1.5265 - val_acc: 0.5804\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.43432\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.1259 - acc: 0.6634 - val_loss: 1.5164 - val_acc: 0.5941\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.43432\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.1183 - acc: 0.6629 - val_loss: 1.5249 - val_acc: 0.5836\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.43432\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.1025 - acc: 0.6657 - val_loss: 1.5035 - val_acc: 0.5983\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.43432\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.0974 - acc: 0.6670 - val_loss: 1.5780 - val_acc: 0.5689\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.43432\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 89s 667ms/step - loss: 1.0446 - acc: 0.6856 - val_loss: 1.4855 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.43432\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.0295 - acc: 0.6886 - val_loss: 1.5029 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.43432\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 89s 665ms/step - loss: 1.0210 - acc: 0.6836 - val_loss: 1.4608 - val_acc: 0.5962\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.43432\n",
      "Fold:  4\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 110s 824ms/step - loss: 3.4262 - acc: 0.0653 - val_loss: 3.1891 - val_acc: 0.1074\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.18906, saving model to best_4.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 3.0105 - acc: 0.1520 - val_loss: 2.7721 - val_acc: 0.1958\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.18906 to 2.77210, saving model to best_4.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 2.7687 - acc: 0.2135 - val_loss: 2.5711 - val_acc: 0.2358\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.77210 to 2.57106, saving model to best_4.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 2.5711 - acc: 0.2680 - val_loss: 2.4191 - val_acc: 0.2905\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.57106 to 2.41912, saving model to best_4.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 2.4145 - acc: 0.2984 - val_loss: 2.2242 - val_acc: 0.3389\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.41912 to 2.22421, saving model to best_4.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 2.3129 - acc: 0.3271 - val_loss: 2.3718 - val_acc: 0.3021\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.22421\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 2.2298 - acc: 0.3509 - val_loss: 2.0509 - val_acc: 0.3853\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.22421 to 2.05088, saving model to best_4.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 91s 678ms/step - loss: 2.1501 - acc: 0.3735 - val_loss: 1.9674 - val_acc: 0.4158\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.05088 to 1.96741, saving model to best_4.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 2.1027 - acc: 0.3842 - val_loss: 1.9206 - val_acc: 0.4295\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.96741 to 1.92065, saving model to best_4.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 2.0231 - acc: 0.4112 - val_loss: 1.9153 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.92065 to 1.91532, saving model to best_4.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.9636 - acc: 0.4276 - val_loss: 1.8771 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.91532 to 1.87709, saving model to best_4.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 89s 664ms/step - loss: 1.9172 - acc: 0.4388 - val_loss: 1.7536 - val_acc: 0.4863\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.87709 to 1.75360, saving model to best_4.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.8621 - acc: 0.4571 - val_loss: 1.7974 - val_acc: 0.4926\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.75360\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.7888 - acc: 0.4746 - val_loss: 1.7333 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.75360 to 1.73334, saving model to best_4.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 91s 682ms/step - loss: 1.7575 - acc: 0.4853 - val_loss: 1.6905 - val_acc: 0.5095\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.73334 to 1.69046, saving model to best_4.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 96s 719ms/step - loss: 1.7252 - acc: 0.4955 - val_loss: 1.7154 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.69046\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 92s 688ms/step - loss: 1.6858 - acc: 0.5016 - val_loss: 1.7181 - val_acc: 0.5011\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.69046\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 96s 717ms/step - loss: 1.6325 - acc: 0.5195 - val_loss: 1.6148 - val_acc: 0.5316\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.69046 to 1.61479, saving model to best_4.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 93s 694ms/step - loss: 1.6059 - acc: 0.5251 - val_loss: 1.6045 - val_acc: 0.5242\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.61479 to 1.60447, saving model to best_4.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 93s 692ms/step - loss: 1.5661 - acc: 0.5365 - val_loss: 1.6206 - val_acc: 0.5242\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60447\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 92s 690ms/step - loss: 1.5527 - acc: 0.5408 - val_loss: 1.5408 - val_acc: 0.5589\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.60447 to 1.54084, saving model to best_4.h5\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 94s 698ms/step - loss: 1.5480 - acc: 0.5483 - val_loss: 1.6407 - val_acc: 0.5116\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.54084\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 94s 705ms/step - loss: 1.5035 - acc: 0.5599 - val_loss: 1.5623 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.54084\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 95s 707ms/step - loss: 1.4728 - acc: 0.5679 - val_loss: 1.5595 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.54084\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 95s 711ms/step - loss: 1.4529 - acc: 0.5699 - val_loss: 1.4841 - val_acc: 0.5674\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.54084 to 1.48409, saving model to best_4.h5\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 95s 708ms/step - loss: 1.4174 - acc: 0.5801 - val_loss: 1.5310 - val_acc: 0.5463\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.48409\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 92s 688ms/step - loss: 1.4246 - acc: 0.5742 - val_loss: 1.5311 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.48409\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.4124 - acc: 0.5789 - val_loss: 1.4976 - val_acc: 0.5621\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.48409\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.3849 - acc: 0.5900 - val_loss: 1.4433 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.48409 to 1.44330, saving model to best_4.h5\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.3669 - acc: 0.5935 - val_loss: 1.5509 - val_acc: 0.5589\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.44330\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 90s 669ms/step - loss: 1.3279 - acc: 0.6069 - val_loss: 1.5503 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.44330\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.3359 - acc: 0.6048 - val_loss: 1.3981 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.44330 to 1.39807, saving model to best_4.h5\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.3155 - acc: 0.6019 - val_loss: 1.4321 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.39807\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.2977 - acc: 0.6113 - val_loss: 1.3891 - val_acc: 0.6137\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.39807 to 1.38915, saving model to best_4.h5\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.2901 - acc: 0.6098 - val_loss: 1.3251 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.38915 to 1.32509, saving model to best_4.h5\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.2902 - acc: 0.6156 - val_loss: 1.3803 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.32509\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.2641 - acc: 0.6179 - val_loss: 1.3981 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.32509\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.2432 - acc: 0.6254 - val_loss: 1.4302 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.32509\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.2331 - acc: 0.6285 - val_loss: 1.5167 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.32509\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.2328 - acc: 0.6331 - val_loss: 1.3464 - val_acc: 0.6326\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.32509\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1651 - acc: 0.6479 - val_loss: 1.2831 - val_acc: 0.6421\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.32509 to 1.28313, saving model to best_4.h5\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.1394 - acc: 0.6569 - val_loss: 1.3926 - val_acc: 0.6105\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.28313\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.1434 - acc: 0.6569 - val_loss: 1.3278 - val_acc: 0.6274\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.28313\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.1280 - acc: 0.6573 - val_loss: 1.3740 - val_acc: 0.6211\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.28313\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.1116 - acc: 0.6670 - val_loss: 1.3204 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.28313\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.1161 - acc: 0.6615 - val_loss: 1.3065 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.28313\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.0669 - acc: 0.6805 - val_loss: 1.3160 - val_acc: 0.6221\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.28313\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.0652 - acc: 0.6802 - val_loss: 1.2745 - val_acc: 0.6305\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.28313 to 1.27448, saving model to best_4.h5\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.0411 - acc: 0.6825 - val_loss: 1.3586 - val_acc: 0.6263\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.27448\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.0155 - acc: 0.6885 - val_loss: 1.3584 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.27448\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.0324 - acc: 0.6914 - val_loss: 1.2722 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.27448 to 1.27223, saving model to best_4.h5\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.0277 - acc: 0.6872 - val_loss: 1.3099 - val_acc: 0.6305\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.27223\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.0259 - acc: 0.6859 - val_loss: 1.2968 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.27223\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.0058 - acc: 0.6961 - val_loss: 1.3827 - val_acc: 0.6084\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.27223\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.0072 - acc: 0.6974 - val_loss: 1.2647 - val_acc: 0.6505\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.27223 to 1.26470, saving model to best_4.h5\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 0.9941 - acc: 0.7005 - val_loss: 1.2785 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.26470\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.0049 - acc: 0.7005 - val_loss: 1.3601 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.26470\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 0.9833 - acc: 0.7061 - val_loss: 1.2839 - val_acc: 0.6568\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.26470\n",
      "Epoch 59/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 0.9860 - acc: 0.7031 - val_loss: 1.3050 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.26470\n",
      "Epoch 60/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 0.9647 - acc: 0.7059 - val_loss: 1.2967 - val_acc: 0.6358\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.26470\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 89s 664ms/step - loss: 0.9366 - acc: 0.7151 - val_loss: 1.3381 - val_acc: 0.6368\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.26470\n",
      "Epoch 62/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.9295 - acc: 0.7151 - val_loss: 1.3187 - val_acc: 0.6358\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.26470\n",
      "Epoch 63/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 0.9403 - acc: 0.7141 - val_loss: 1.2598 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.26470 to 1.25985, saving model to best_4.h5\n",
      "Epoch 64/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 0.9195 - acc: 0.7189 - val_loss: 1.3069 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.25985\n",
      "Epoch 65/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 0.9333 - acc: 0.7178 - val_loss: 1.2448 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.25985 to 1.24476, saving model to best_4.h5\n",
      "Epoch 66/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 0.9073 - acc: 0.7233 - val_loss: 1.2384 - val_acc: 0.6632\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.24476 to 1.23838, saving model to best_4.h5\n",
      "Epoch 67/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 0.9167 - acc: 0.7161 - val_loss: 1.2988 - val_acc: 0.6653\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.23838\n",
      "Epoch 68/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 0.9049 - acc: 0.7226 - val_loss: 1.2441 - val_acc: 0.6568\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.23838\n",
      "Epoch 69/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 0.9061 - acc: 0.7202 - val_loss: 1.2855 - val_acc: 0.6568\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.23838\n",
      "Epoch 70/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 0.9090 - acc: 0.7252 - val_loss: 1.2721 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.23838\n",
      "Epoch 71/500\n",
      "134/134 [==============================] - 92s 687ms/step - loss: 0.8856 - acc: 0.7230 - val_loss: 1.2600 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.23838\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "Epoch 72/500\n",
      "134/134 [==============================] - 92s 686ms/step - loss: 0.8911 - acc: 0.7322 - val_loss: 1.2048 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.23838 to 1.20484, saving model to best_4.h5\n",
      "Epoch 73/500\n",
      "134/134 [==============================] - 89s 662ms/step - loss: 0.8673 - acc: 0.7350 - val_loss: 1.2636 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.20484\n",
      "Epoch 74/500\n",
      "134/134 [==============================] - 90s 674ms/step - loss: 0.8648 - acc: 0.7354 - val_loss: 1.2380 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.20484\n",
      "Epoch 75/500\n",
      "134/134 [==============================] - 89s 666ms/step - loss: 0.8638 - acc: 0.7374 - val_loss: 1.2636 - val_acc: 0.6589\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.20484\n",
      "Epoch 76/500\n",
      "134/134 [==============================] - 89s 666ms/step - loss: 0.8526 - acc: 0.7395 - val_loss: 1.2965 - val_acc: 0.6474\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.20484\n",
      "Epoch 77/500\n",
      "134/134 [==============================] - 90s 674ms/step - loss: 0.8631 - acc: 0.7384 - val_loss: 1.2422 - val_acc: 0.6684\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.20484\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "Epoch 78/500\n",
      "134/134 [==============================] - 90s 668ms/step - loss: 0.8342 - acc: 0.7455 - val_loss: 1.2515 - val_acc: 0.6537\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.20484\n",
      "Epoch 79/500\n",
      "134/134 [==============================] - 90s 675ms/step - loss: 0.8399 - acc: 0.7433 - val_loss: 1.2475 - val_acc: 0.6695\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.20484\n",
      "Epoch 80/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.8234 - acc: 0.7453 - val_loss: 1.2090 - val_acc: 0.6695\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.20484\n",
      "Fold:  5\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 110s 820ms/step - loss: 3.3997 - acc: 0.0778 - val_loss: 3.1544 - val_acc: 0.1247\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.15436, saving model to best_5.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 85s 635ms/step - loss: 2.9498 - acc: 0.1590 - val_loss: 2.8488 - val_acc: 0.1871\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.15436 to 2.84880, saving model to best_5.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 2.7554 - acc: 0.2105 - val_loss: 2.6911 - val_acc: 0.2378\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.84880 to 2.69108, saving model to best_5.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 85s 637ms/step - loss: 2.5747 - acc: 0.2674 - val_loss: 2.5184 - val_acc: 0.2632\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.69108 to 2.51843, saving model to best_5.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 2.4286 - acc: 0.2946 - val_loss: 2.4184 - val_acc: 0.3097\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.51843 to 2.41845, saving model to best_5.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 2.2929 - acc: 0.3279 - val_loss: 2.2609 - val_acc: 0.3541\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.41845 to 2.26092, saving model to best_5.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 2.1819 - acc: 0.3641 - val_loss: 2.1863 - val_acc: 0.3626\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.26092 to 2.18633, saving model to best_5.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 85s 638ms/step - loss: 2.1280 - acc: 0.3831 - val_loss: 2.1130 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.18633 to 2.11303, saving model to best_5.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 2.0619 - acc: 0.4041 - val_loss: 2.1329 - val_acc: 0.3858\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.11303\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.9530 - acc: 0.4334 - val_loss: 2.0595 - val_acc: 0.4112\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.11303 to 2.05953, saving model to best_5.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.8854 - acc: 0.4490 - val_loss: 1.9709 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.05953 to 1.97092, saving model to best_5.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.8319 - acc: 0.4691 - val_loss: 1.9031 - val_acc: 0.4556\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.97092 to 1.90311, saving model to best_5.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.7888 - acc: 0.4763 - val_loss: 1.8361 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.90311 to 1.83609, saving model to best_5.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.7271 - acc: 0.4928 - val_loss: 1.7610 - val_acc: 0.5127\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.83609 to 1.76098, saving model to best_5.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 1.6904 - acc: 0.4990 - val_loss: 1.7225 - val_acc: 0.5137\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.76098 to 1.72254, saving model to best_5.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.6670 - acc: 0.5096 - val_loss: 1.7334 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.72254\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.6102 - acc: 0.5195 - val_loss: 1.7801 - val_acc: 0.4778\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.72254\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.6077 - acc: 0.5223 - val_loss: 1.6833 - val_acc: 0.5148\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.72254 to 1.68326, saving model to best_5.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.5415 - acc: 0.5445 - val_loss: 1.5904 - val_acc: 0.5285\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.68326 to 1.59036, saving model to best_5.h5\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 86s 639ms/step - loss: 1.5307 - acc: 0.5481 - val_loss: 1.6947 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.59036\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.5031 - acc: 0.5516 - val_loss: 1.6000 - val_acc: 0.5518\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.59036\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.4708 - acc: 0.5602 - val_loss: 1.5666 - val_acc: 0.5370\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.59036 to 1.56660, saving model to best_5.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.4456 - acc: 0.5693 - val_loss: 1.5855 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.56660\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 85s 638ms/step - loss: 1.4152 - acc: 0.5783 - val_loss: 1.5373 - val_acc: 0.5603\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.56660 to 1.53727, saving model to best_5.h5\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.3999 - acc: 0.5906 - val_loss: 1.6054 - val_acc: 0.5412\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.53727\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.3923 - acc: 0.5859 - val_loss: 1.5290 - val_acc: 0.5444\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.53727 to 1.52900, saving model to best_5.h5\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.3394 - acc: 0.6060 - val_loss: 1.6030 - val_acc: 0.5444\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.52900\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.3226 - acc: 0.6063 - val_loss: 1.4953 - val_acc: 0.5719\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.52900 to 1.49528, saving model to best_5.h5\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.3436 - acc: 0.5974 - val_loss: 1.5105 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.49528\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.3012 - acc: 0.6067 - val_loss: 1.5013 - val_acc: 0.5677\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.49528\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.2857 - acc: 0.6160 - val_loss: 1.5072 - val_acc: 0.5655\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.49528\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 1.2790 - acc: 0.6210 - val_loss: 1.5342 - val_acc: 0.5655\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.49528\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.2775 - acc: 0.6157 - val_loss: 1.4645 - val_acc: 0.5825\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.49528 to 1.46450, saving model to best_5.h5\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.2473 - acc: 0.6292 - val_loss: 1.4795 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.46450\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.2328 - acc: 0.6289 - val_loss: 1.4889 - val_acc: 0.5645\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.46450\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.2038 - acc: 0.6388 - val_loss: 1.4479 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.46450 to 1.44792, saving model to best_5.h5\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 653ms/step - loss: 1.2388 - acc: 0.6275 - val_loss: 1.4243 - val_acc: 0.5846\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.44792 to 1.42429, saving model to best_5.h5\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.1876 - acc: 0.6420 - val_loss: 1.4315 - val_acc: 0.5877\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.42429\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1823 - acc: 0.6469 - val_loss: 1.3995 - val_acc: 0.5983\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.42429 to 1.39950, saving model to best_5.h5\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.1812 - acc: 0.6418 - val_loss: 1.4353 - val_acc: 0.5951\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.39950\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.1519 - acc: 0.6561 - val_loss: 1.5245 - val_acc: 0.5751\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.39950\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.1528 - acc: 0.6519 - val_loss: 1.4171 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.39950\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.1699 - acc: 0.6443 - val_loss: 1.4276 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.39950\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.1242 - acc: 0.6578 - val_loss: 1.4465 - val_acc: 0.6047\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.39950\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.0637 - acc: 0.6795 - val_loss: 1.4017 - val_acc: 0.6205\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.39950\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.0701 - acc: 0.6842 - val_loss: 1.4855 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.39950\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.0445 - acc: 0.6861 - val_loss: 1.3981 - val_acc: 0.6121\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.39950 to 1.39808, saving model to best_5.h5\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.0369 - acc: 0.6803 - val_loss: 1.3976 - val_acc: 0.6121\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.39808 to 1.39757, saving model to best_5.h5\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0379 - acc: 0.6852 - val_loss: 1.3936 - val_acc: 0.6057\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.39757 to 1.39358, saving model to best_5.h5\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.0210 - acc: 0.6889 - val_loss: 1.3868 - val_acc: 0.6163\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.39358 to 1.38680, saving model to best_5.h5\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.0201 - acc: 0.6911 - val_loss: 1.4137 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.38680\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 0.9991 - acc: 0.6959 - val_loss: 1.4285 - val_acc: 0.6089\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.38680\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.0046 - acc: 0.6966 - val_loss: 1.4366 - val_acc: 0.6025\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.38680\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.0132 - acc: 0.6945 - val_loss: 1.3937 - val_acc: 0.6089\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.38680\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 0.9790 - acc: 0.7042 - val_loss: 1.4058 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.38680\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 0.9465 - acc: 0.7082 - val_loss: 1.3669 - val_acc: 0.6184\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.38680 to 1.36687, saving model to best_5.h5\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 0.9326 - acc: 0.7126 - val_loss: 1.4164 - val_acc: 0.6131\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.36687\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 0.9257 - acc: 0.7164 - val_loss: 1.3930 - val_acc: 0.6258\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.36687\n",
      "Epoch 59/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 0.9074 - acc: 0.7161 - val_loss: 1.4254 - val_acc: 0.6099\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.36687\n",
      "Epoch 60/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 0.9016 - acc: 0.7232 - val_loss: 1.4017 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.36687\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 0.9244 - acc: 0.7227 - val_loss: 1.4123 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.36687\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 62/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 0.8691 - acc: 0.7322 - val_loss: 1.3861 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.36687\n",
      "Epoch 63/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 0.8668 - acc: 0.7375 - val_loss: 1.3782 - val_acc: 0.6258\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.36687\n",
      "Epoch 64/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.8650 - acc: 0.7336 - val_loss: 1.3905 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.36687\n",
      "Fold:  6\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 107s 799ms/step - loss: 3.4378 - acc: 0.0679 - val_loss: 3.2272 - val_acc: 0.1005\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.22721, saving model to best_6.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 3.0540 - acc: 0.1391 - val_loss: 2.9420 - val_acc: 0.1799\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.22721 to 2.94198, saving model to best_6.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 2.7874 - acc: 0.2020 - val_loss: 2.6864 - val_acc: 0.2476\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.94198 to 2.68638, saving model to best_6.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 2.5655 - acc: 0.2620 - val_loss: 2.5292 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.68638 to 2.52920, saving model to best_6.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 2.3998 - acc: 0.3024 - val_loss: 2.4946 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.52920 to 2.49460, saving model to best_6.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 2.2909 - acc: 0.3305 - val_loss: 2.4240 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.49460 to 2.42396, saving model to best_6.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 2.2045 - acc: 0.3635 - val_loss: 2.2841 - val_acc: 0.3471\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.42396 to 2.28412, saving model to best_6.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 2.1370 - acc: 0.3736 - val_loss: 2.2660 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.28412 to 2.26598, saving model to best_6.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 2.0502 - acc: 0.4007 - val_loss: 2.1455 - val_acc: 0.3926\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.26598 to 2.14555, saving model to best_6.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 85s 637ms/step - loss: 1.9870 - acc: 0.4213 - val_loss: 2.1232 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.14555 to 2.12320, saving model to best_6.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.9457 - acc: 0.4356 - val_loss: 1.9171 - val_acc: 0.4497\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.12320 to 1.91714, saving model to best_6.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.8350 - acc: 0.4623 - val_loss: 1.9203 - val_acc: 0.4593\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.91714\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.8127 - acc: 0.4693 - val_loss: 2.0159 - val_acc: 0.4466\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.91714\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.7609 - acc: 0.4852 - val_loss: 1.8464 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.91714 to 1.84637, saving model to best_6.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 86s 640ms/step - loss: 1.7046 - acc: 0.5051 - val_loss: 1.7698 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.84637 to 1.76982, saving model to best_6.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.6695 - acc: 0.5097 - val_loss: 1.8077 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.76982\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.6111 - acc: 0.5267 - val_loss: 1.7145 - val_acc: 0.4931\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.76982 to 1.71446, saving model to best_6.h5\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.5868 - acc: 0.5308 - val_loss: 1.7571 - val_acc: 0.4963\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.71446\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 1.5587 - acc: 0.5437 - val_loss: 1.6972 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.71446 to 1.69724, saving model to best_6.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.5354 - acc: 0.5462 - val_loss: 1.6736 - val_acc: 0.5344\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.69724 to 1.67360, saving model to best_6.h5\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.5052 - acc: 0.5597 - val_loss: 1.6711 - val_acc: 0.5238\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.67360 to 1.67111, saving model to best_6.h5\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 89s 665ms/step - loss: 1.4780 - acc: 0.5645 - val_loss: 1.6395 - val_acc: 0.5481\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.67111 to 1.63945, saving model to best_6.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.4392 - acc: 0.5728 - val_loss: 1.6813 - val_acc: 0.5270\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.63945\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 1.4230 - acc: 0.5819 - val_loss: 1.5526 - val_acc: 0.5534\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.63945 to 1.55264, saving model to best_6.h5\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.4098 - acc: 0.5837 - val_loss: 1.5998 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.55264\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.3996 - acc: 0.5861 - val_loss: 1.5297 - val_acc: 0.5704\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.55264 to 1.52974, saving model to best_6.h5\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 85s 637ms/step - loss: 1.3497 - acc: 0.5969 - val_loss: 1.5667 - val_acc: 0.5598\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.52974\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.3439 - acc: 0.6035 - val_loss: 1.5830 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.52974\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.3105 - acc: 0.6063 - val_loss: 1.6013 - val_acc: 0.5577\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.52974\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.3128 - acc: 0.6098 - val_loss: 1.5768 - val_acc: 0.5344\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.52974\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.2915 - acc: 0.6132 - val_loss: 1.5644 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.52974\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.2271 - acc: 0.6346 - val_loss: 1.5262 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.52974 to 1.52615, saving model to best_6.h5\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.2076 - acc: 0.6402 - val_loss: 1.5297 - val_acc: 0.5661\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.52615\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.1965 - acc: 0.6385 - val_loss: 1.5128 - val_acc: 0.5693\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.52615 to 1.51277, saving model to best_6.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 1.1861 - acc: 0.6370 - val_loss: 1.5228 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.51277\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 86s 642ms/step - loss: 1.1616 - acc: 0.6489 - val_loss: 1.5271 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.51277\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.1606 - acc: 0.6561 - val_loss: 1.4702 - val_acc: 0.5989\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.51277 to 1.47018, saving model to best_6.h5\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 1.1591 - acc: 0.6519 - val_loss: 1.4848 - val_acc: 0.5788\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.47018\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.1344 - acc: 0.6602 - val_loss: 1.4456 - val_acc: 0.5989\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.47018 to 1.44561, saving model to best_6.h5\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.1252 - acc: 0.6618 - val_loss: 1.5501 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.44561\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 86s 643ms/step - loss: 1.1239 - acc: 0.6623 - val_loss: 1.4814 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.44561\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.0975 - acc: 0.6685 - val_loss: 1.4702 - val_acc: 0.5947\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.44561\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.0968 - acc: 0.6695 - val_loss: 1.4839 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.44561\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.0876 - acc: 0.6723 - val_loss: 1.4231 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.44561 to 1.42312, saving model to best_6.h5\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.0771 - acc: 0.6729 - val_loss: 1.4517 - val_acc: 0.5905\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.42312\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.0600 - acc: 0.6756 - val_loss: 1.4720 - val_acc: 0.5757\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.42312\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.0591 - acc: 0.6808 - val_loss: 1.4533 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.42312\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.0650 - acc: 0.6798 - val_loss: 1.4393 - val_acc: 0.5894\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.42312\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.0529 - acc: 0.6838 - val_loss: 1.4848 - val_acc: 0.5968\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.42312\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 0.9878 - acc: 0.7008 - val_loss: 1.3752 - val_acc: 0.6138\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.42312 to 1.37520, saving model to best_6.h5\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 91s 680ms/step - loss: 0.9836 - acc: 0.7028 - val_loss: 1.4349 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.37520\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 95s 712ms/step - loss: 0.9906 - acc: 0.7028 - val_loss: 1.5126 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.37520\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 97s 724ms/step - loss: 0.9902 - acc: 0.6989 - val_loss: 1.4271 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.37520\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 95s 706ms/step - loss: 0.9725 - acc: 0.7059 - val_loss: 1.4463 - val_acc: 0.6021\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.37520\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 89s 666ms/step - loss: 0.9526 - acc: 0.7134 - val_loss: 1.4971 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.37520\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 0.9310 - acc: 0.7186 - val_loss: 1.4431 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.37520\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 0.9356 - acc: 0.7156 - val_loss: 1.4272 - val_acc: 0.6063\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.37520\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 88s 660ms/step - loss: 0.9079 - acc: 0.7267 - val_loss: 1.4351 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.37520\n",
      "Fold:  7\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 109s 812ms/step - loss: 3.4185 - acc: 0.0639 - val_loss: 3.4006 - val_acc: 0.0647\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.40056, saving model to best_7.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 3.0806 - acc: 0.1224 - val_loss: 2.9439 - val_acc: 0.1686\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.40056 to 2.94390, saving model to best_7.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 90s 669ms/step - loss: 2.8393 - acc: 0.1885 - val_loss: 2.7256 - val_acc: 0.2142\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.94390 to 2.72564, saving model to best_7.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 89s 667ms/step - loss: 2.6251 - acc: 0.2473 - val_loss: 2.5598 - val_acc: 0.2651\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.72564 to 2.55979, saving model to best_7.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 652ms/step - loss: 2.4397 - acc: 0.3033 - val_loss: 2.4188 - val_acc: 0.2906\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.55979 to 2.41884, saving model to best_7.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 91s 680ms/step - loss: 2.3366 - acc: 0.3189 - val_loss: 2.3007 - val_acc: 0.3277\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.41884 to 2.30066, saving model to best_7.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 2.2170 - acc: 0.3557 - val_loss: 2.2184 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.30066 to 2.21838, saving model to best_7.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 92s 690ms/step - loss: 2.1355 - acc: 0.3743 - val_loss: 2.1879 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.21838 to 2.18789, saving model to best_7.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 2.0515 - acc: 0.4036 - val_loss: 2.1663 - val_acc: 0.3701\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.18789 to 2.16630, saving model to best_7.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 94s 703ms/step - loss: 1.9849 - acc: 0.4271 - val_loss: 2.0225 - val_acc: 0.3955\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.16630 to 2.02252, saving model to best_7.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 95s 708ms/step - loss: 1.9270 - acc: 0.4387 - val_loss: 2.0373 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.02252\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 94s 705ms/step - loss: 1.8588 - acc: 0.4573 - val_loss: 1.9827 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.02252 to 1.98272, saving model to best_7.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 93s 693ms/step - loss: 1.8050 - acc: 0.4730 - val_loss: 1.9246 - val_acc: 0.4475\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.98272 to 1.92458, saving model to best_7.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.7414 - acc: 0.4903 - val_loss: 1.9687 - val_acc: 0.4358\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.92458\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 94s 702ms/step - loss: 1.7014 - acc: 0.5059 - val_loss: 1.7739 - val_acc: 0.4761\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.92458 to 1.77391, saving model to best_7.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 94s 704ms/step - loss: 1.6516 - acc: 0.5139 - val_loss: 1.7791 - val_acc: 0.4942\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.77391\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 1.6199 - acc: 0.5275 - val_loss: 1.7483 - val_acc: 0.5058\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.77391 to 1.74829, saving model to best_7.h5\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 95s 709ms/step - loss: 1.5945 - acc: 0.5286 - val_loss: 1.8314 - val_acc: 0.4624\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.74829\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 94s 704ms/step - loss: 1.5596 - acc: 0.5411 - val_loss: 1.6964 - val_acc: 0.4889\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.74829 to 1.69641, saving model to best_7.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 93s 693ms/step - loss: 1.5267 - acc: 0.5472 - val_loss: 1.7189 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.69641\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 100s 743ms/step - loss: 1.5085 - acc: 0.5520 - val_loss: 1.6427 - val_acc: 0.5345\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.69641 to 1.64274, saving model to best_7.h5\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 95s 711ms/step - loss: 1.4743 - acc: 0.5622 - val_loss: 1.5982 - val_acc: 0.5429\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.64274 to 1.59816, saving model to best_7.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 92s 685ms/step - loss: 1.4693 - acc: 0.5657 - val_loss: 1.6175 - val_acc: 0.5196\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.59816\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 1.4321 - acc: 0.5689 - val_loss: 1.6041 - val_acc: 0.5323\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.59816\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.4146 - acc: 0.5784 - val_loss: 1.5726 - val_acc: 0.5557\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.59816 to 1.57259, saving model to best_7.h5\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.3959 - acc: 0.5853 - val_loss: 1.5994 - val_acc: 0.5408\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.57259\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.3765 - acc: 0.5920 - val_loss: 1.5406 - val_acc: 0.5483\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.57259 to 1.54060, saving model to best_7.h5\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.3641 - acc: 0.5937 - val_loss: 1.6287 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.54060\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.3342 - acc: 0.6025 - val_loss: 1.5570 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.54060\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.3191 - acc: 0.6031 - val_loss: 1.5383 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.54060 to 1.53834, saving model to best_7.h5\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.3121 - acc: 0.6068 - val_loss: 1.5651 - val_acc: 0.5652\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.53834\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.3088 - acc: 0.6102 - val_loss: 1.5607 - val_acc: 0.5578\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.53834\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.2888 - acc: 0.6104 - val_loss: 1.5400 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.53834\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.2552 - acc: 0.6240 - val_loss: 1.5376 - val_acc: 0.5652\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.53834 to 1.53763, saving model to best_7.h5\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 1.2524 - acc: 0.6257 - val_loss: 1.5771 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.53763\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.2469 - acc: 0.6320 - val_loss: 1.4771 - val_acc: 0.5737\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.53763 to 1.47712, saving model to best_7.h5\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 87s 649ms/step - loss: 1.2303 - acc: 0.6317 - val_loss: 1.5734 - val_acc: 0.5525\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.47712\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.2275 - acc: 0.6278 - val_loss: 1.5087 - val_acc: 0.5663\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.47712\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 87s 648ms/step - loss: 1.1946 - acc: 0.6351 - val_loss: 1.5637 - val_acc: 0.5589\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.47712\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 87s 651ms/step - loss: 1.1928 - acc: 0.6395 - val_loss: 1.5470 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.47712\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 88s 657ms/step - loss: 1.2044 - acc: 0.6441 - val_loss: 1.4675 - val_acc: 0.5811\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.47712 to 1.46754, saving model to best_7.h5\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.1823 - acc: 0.6407 - val_loss: 1.4419 - val_acc: 0.5843\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.46754 to 1.44186, saving model to best_7.h5\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 1.1729 - acc: 0.6468 - val_loss: 1.4940 - val_acc: 0.5801\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.44186\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.1474 - acc: 0.6500 - val_loss: 1.5571 - val_acc: 0.5695\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.44186\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.1514 - acc: 0.6535 - val_loss: 1.5063 - val_acc: 0.5599\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.44186\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.1408 - acc: 0.6499 - val_loss: 1.4936 - val_acc: 0.5737\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.44186\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 88s 659ms/step - loss: 1.1162 - acc: 0.6607 - val_loss: 1.5427 - val_acc: 0.5663\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.44186\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 1.0586 - acc: 0.6829 - val_loss: 1.4568 - val_acc: 0.5854\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.44186\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.0609 - acc: 0.6783 - val_loss: 1.4787 - val_acc: 0.5748\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.44186\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.0440 - acc: 0.6815 - val_loss: 1.4332 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.44186 to 1.43324, saving model to best_7.h5\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.0221 - acc: 0.6907 - val_loss: 1.3896 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.43324 to 1.38961, saving model to best_7.h5\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 85s 637ms/step - loss: 1.0276 - acc: 0.6904 - val_loss: 1.4468 - val_acc: 0.6045\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.38961\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 1.0108 - acc: 0.6909 - val_loss: 1.4260 - val_acc: 0.6066\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.38961\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 88s 653ms/step - loss: 1.0241 - acc: 0.6868 - val_loss: 1.4400 - val_acc: 0.6098\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.38961\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 0.9920 - acc: 0.6986 - val_loss: 1.5067 - val_acc: 0.5875\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.38961\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 0.9961 - acc: 0.6900 - val_loss: 1.4554 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.38961\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 96s 720ms/step - loss: 0.9649 - acc: 0.7075 - val_loss: 1.4714 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.38961\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 94s 703ms/step - loss: 0.9550 - acc: 0.7084 - val_loss: 1.4358 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.38961\n",
      "Epoch 59/500\n",
      "134/134 [==============================] - 94s 703ms/step - loss: 0.9429 - acc: 0.7100 - val_loss: 1.4430 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.38961\n",
      "Fold:  8\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 117s 873ms/step - loss: 3.3677 - acc: 0.0785 - val_loss: 3.0251 - val_acc: 0.1518\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.02515, saving model to best_8.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 2.9076 - acc: 0.1730 - val_loss: 2.8212 - val_acc: 0.2070\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.02515 to 2.82117, saving model to best_8.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 93s 693ms/step - loss: 2.6858 - acc: 0.2293 - val_loss: 2.6569 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82117 to 2.65691, saving model to best_8.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 2.4793 - acc: 0.2825 - val_loss: 2.4500 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.65691 to 2.44997, saving model to best_8.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 88s 658ms/step - loss: 2.3603 - acc: 0.3181 - val_loss: 2.3302 - val_acc: 0.3312\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.44997 to 2.33022, saving model to best_8.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 86s 644ms/step - loss: 2.2393 - acc: 0.3467 - val_loss: 2.2424 - val_acc: 0.3715\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.33022 to 2.24243, saving model to best_8.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 2.1579 - acc: 0.3746 - val_loss: 2.1572 - val_acc: 0.3726\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.24243 to 2.15715, saving model to best_8.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 2.0622 - acc: 0.4035 - val_loss: 2.1566 - val_acc: 0.3917\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.15715 to 2.15662, saving model to best_8.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 86s 645ms/step - loss: 2.0015 - acc: 0.4194 - val_loss: 2.1151 - val_acc: 0.3938\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.15662 to 2.11512, saving model to best_8.h5\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 89s 662ms/step - loss: 1.9162 - acc: 0.4413 - val_loss: 2.0288 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.11512 to 2.02879, saving model to best_8.h5\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 94s 700ms/step - loss: 1.8701 - acc: 0.4518 - val_loss: 1.9520 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.02879 to 1.95204, saving model to best_8.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 91s 680ms/step - loss: 1.8028 - acc: 0.4761 - val_loss: 1.9475 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.95204 to 1.94746, saving model to best_8.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 94s 703ms/step - loss: 1.7595 - acc: 0.4900 - val_loss: 1.8190 - val_acc: 0.4894\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.94746 to 1.81897, saving model to best_8.h5\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 1.7145 - acc: 0.4979 - val_loss: 1.8426 - val_acc: 0.4724\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.81897\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.6804 - acc: 0.5091 - val_loss: 1.8418 - val_acc: 0.4766\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.81897\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 93s 697ms/step - loss: 1.6596 - acc: 0.5102 - val_loss: 1.8656 - val_acc: 0.4777\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.81897\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 94s 704ms/step - loss: 1.6006 - acc: 0.5316 - val_loss: 1.8449 - val_acc: 0.4915\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.81897\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 93s 694ms/step - loss: 1.5776 - acc: 0.5336 - val_loss: 1.8342 - val_acc: 0.4841\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.81897\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 95s 707ms/step - loss: 1.4932 - acc: 0.5619 - val_loss: 1.6585 - val_acc: 0.5329\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.81897 to 1.65850, saving model to best_8.h5\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.4470 - acc: 0.5729 - val_loss: 1.6663 - val_acc: 0.5308\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.65850\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 92s 688ms/step - loss: 1.4395 - acc: 0.5673 - val_loss: 1.7035 - val_acc: 0.5382\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.65850\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 91s 681ms/step - loss: 1.4214 - acc: 0.5774 - val_loss: 1.6696 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.65850\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 96s 714ms/step - loss: 1.4194 - acc: 0.5756 - val_loss: 1.5794 - val_acc: 0.5552\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.65850 to 1.57937, saving model to best_8.h5\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 94s 699ms/step - loss: 1.3707 - acc: 0.5957 - val_loss: 1.7067 - val_acc: 0.5318\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.57937\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 97s 722ms/step - loss: 1.3680 - acc: 0.5972 - val_loss: 1.6570 - val_acc: 0.5414\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.57937\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 96s 717ms/step - loss: 1.3653 - acc: 0.5976 - val_loss: 1.6230 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.57937\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 1.3405 - acc: 0.6001 - val_loss: 1.5586 - val_acc: 0.5584\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.57937 to 1.55862, saving model to best_8.h5\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 97s 721ms/step - loss: 1.3295 - acc: 0.6050 - val_loss: 1.6121 - val_acc: 0.5626\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.55862\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 93s 691ms/step - loss: 1.3151 - acc: 0.6108 - val_loss: 1.6619 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.55862\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 96s 714ms/step - loss: 1.3016 - acc: 0.6091 - val_loss: 1.5976 - val_acc: 0.5510\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.55862\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 93s 694ms/step - loss: 1.2704 - acc: 0.6205 - val_loss: 1.5960 - val_acc: 0.5478\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.55862\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 92s 690ms/step - loss: 1.2772 - acc: 0.6138 - val_loss: 1.5139 - val_acc: 0.5637\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.55862 to 1.51385, saving model to best_8.h5\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 91s 677ms/step - loss: 1.2652 - acc: 0.6222 - val_loss: 1.5611 - val_acc: 0.5626\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.51385\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 93s 697ms/step - loss: 1.2233 - acc: 0.6302 - val_loss: 1.5149 - val_acc: 0.5849\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.51385\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 92s 686ms/step - loss: 1.2318 - acc: 0.6336 - val_loss: 1.5200 - val_acc: 0.5701\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.51385\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 92s 687ms/step - loss: 1.2092 - acc: 0.6389 - val_loss: 1.5148 - val_acc: 0.5701\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.51385\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 94s 699ms/step - loss: 1.1985 - acc: 0.6415 - val_loss: 1.6691 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.51385\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 95s 708ms/step - loss: 1.1501 - acc: 0.6537 - val_loss: 1.5517 - val_acc: 0.5743\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.51385\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 94s 703ms/step - loss: 1.1437 - acc: 0.6585 - val_loss: 1.5190 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.51385\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 93s 691ms/step - loss: 1.1328 - acc: 0.6569 - val_loss: 1.5236 - val_acc: 0.5722\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.51385\n",
      "Fold:  9\n",
      "##################################################\n",
      "Epoch 1/500\n",
      "134/134 [==============================] - 112s 837ms/step - loss: 3.4031 - acc: 0.0722 - val_loss: 3.0389 - val_acc: 0.1603\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.03890, saving model to best_9.h5\n",
      "Epoch 2/500\n",
      "134/134 [==============================] - 90s 670ms/step - loss: 2.9420 - acc: 0.1579 - val_loss: 2.7792 - val_acc: 0.2051\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.03890 to 2.77918, saving model to best_9.h5\n",
      "Epoch 3/500\n",
      "134/134 [==============================] - 90s 671ms/step - loss: 2.7519 - acc: 0.2123 - val_loss: 2.5561 - val_acc: 0.2938\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.77918 to 2.55611, saving model to best_9.h5\n",
      "Epoch 4/500\n",
      "134/134 [==============================] - 90s 675ms/step - loss: 2.5434 - acc: 0.2656 - val_loss: 2.4318 - val_acc: 0.2938\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.55611 to 2.43184, saving model to best_9.h5\n",
      "Epoch 5/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 2.3640 - acc: 0.3159 - val_loss: 2.2898 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.43184 to 2.28985, saving model to best_9.h5\n",
      "Epoch 6/500\n",
      "134/134 [==============================] - 87s 646ms/step - loss: 2.2291 - acc: 0.3515 - val_loss: 2.2786 - val_acc: 0.3579\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.28985 to 2.27856, saving model to best_9.h5\n",
      "Epoch 7/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 2.1538 - acc: 0.3756 - val_loss: 2.1265 - val_acc: 0.3846\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.27856 to 2.12649, saving model to best_9.h5\n",
      "Epoch 8/500\n",
      "134/134 [==============================] - 87s 647ms/step - loss: 2.0711 - acc: 0.3996 - val_loss: 2.0034 - val_acc: 0.4241\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.12649 to 2.00345, saving model to best_9.h5\n",
      "Epoch 9/500\n",
      "134/134 [==============================] - 86s 639ms/step - loss: 2.0161 - acc: 0.4156 - val_loss: 2.1445 - val_acc: 0.3878\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.00345\n",
      "Epoch 10/500\n",
      "134/134 [==============================] - 88s 654ms/step - loss: 1.9779 - acc: 0.4265 - val_loss: 2.0094 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.00345\n",
      "Epoch 11/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.8956 - acc: 0.4456 - val_loss: 1.9268 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.00345 to 1.92678, saving model to best_9.h5\n",
      "Epoch 12/500\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 1.8376 - acc: 0.4662 - val_loss: 1.9202 - val_acc: 0.4434\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.92678 to 1.92021, saving model to best_9.h5\n",
      "Epoch 13/500\n",
      "134/134 [==============================] - 86s 641ms/step - loss: 1.8099 - acc: 0.4681 - val_loss: 1.9298 - val_acc: 0.4476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.92021\n",
      "Epoch 14/500\n",
      "134/134 [==============================] - 89s 665ms/step - loss: 1.7436 - acc: 0.4901 - val_loss: 1.7369 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.92021 to 1.73690, saving model to best_9.h5\n",
      "Epoch 15/500\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 1.6970 - acc: 0.5020 - val_loss: 1.7260 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.73690 to 1.72604, saving model to best_9.h5\n",
      "Epoch 16/500\n",
      "134/134 [==============================] - 87s 650ms/step - loss: 1.6588 - acc: 0.5185 - val_loss: 1.7617 - val_acc: 0.5064\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.72604\n",
      "Epoch 17/500\n",
      "134/134 [==============================] - 88s 655ms/step - loss: 1.6332 - acc: 0.5198 - val_loss: 1.7052 - val_acc: 0.5085\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.72604 to 1.70521, saving model to best_9.h5\n",
      "Epoch 18/500\n",
      "134/134 [==============================] - 95s 705ms/step - loss: 1.5987 - acc: 0.5287 - val_loss: 1.6050 - val_acc: 0.5502\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.70521 to 1.60498, saving model to best_9.h5\n",
      "Epoch 19/500\n",
      "134/134 [==============================] - 92s 685ms/step - loss: 1.5467 - acc: 0.5430 - val_loss: 1.6606 - val_acc: 0.5321\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60498\n",
      "Epoch 20/500\n",
      "134/134 [==============================] - 94s 700ms/step - loss: 1.5330 - acc: 0.5510 - val_loss: 1.5867 - val_acc: 0.5427\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.60498 to 1.58668, saving model to best_9.h5\n",
      "Epoch 21/500\n",
      "134/134 [==============================] - 94s 699ms/step - loss: 1.4981 - acc: 0.5544 - val_loss: 1.6430 - val_acc: 0.5406\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.58668\n",
      "Epoch 22/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.5039 - acc: 0.5554 - val_loss: 1.5825 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.58668 to 1.58253, saving model to best_9.h5\n",
      "Epoch 23/500\n",
      "134/134 [==============================] - 93s 697ms/step - loss: 1.4820 - acc: 0.5612 - val_loss: 1.6298 - val_acc: 0.5470\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.58253\n",
      "Epoch 24/500\n",
      "134/134 [==============================] - 99s 739ms/step - loss: 1.4426 - acc: 0.5758 - val_loss: 1.5634 - val_acc: 0.5641\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.58253 to 1.56343, saving model to best_9.h5\n",
      "Epoch 25/500\n",
      "134/134 [==============================] - 98s 731ms/step - loss: 1.4266 - acc: 0.5806 - val_loss: 1.6445 - val_acc: 0.5406\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.56343\n",
      "Epoch 26/500\n",
      "134/134 [==============================] - 97s 720ms/step - loss: 1.4101 - acc: 0.5832 - val_loss: 1.4802 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.56343 to 1.48023, saving model to best_9.h5\n",
      "Epoch 27/500\n",
      "134/134 [==============================] - 95s 709ms/step - loss: 1.3996 - acc: 0.5831 - val_loss: 1.5463 - val_acc: 0.5726\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.48023\n",
      "Epoch 28/500\n",
      "134/134 [==============================] - 97s 723ms/step - loss: 1.3646 - acc: 0.5892 - val_loss: 1.4636 - val_acc: 0.5897\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.48023 to 1.46359, saving model to best_9.h5\n",
      "Epoch 29/500\n",
      "134/134 [==============================] - 97s 726ms/step - loss: 1.3232 - acc: 0.6043 - val_loss: 1.5183 - val_acc: 0.5705\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.46359\n",
      "Epoch 30/500\n",
      "134/134 [==============================] - 96s 716ms/step - loss: 1.3389 - acc: 0.6025 - val_loss: 1.4669 - val_acc: 0.5769\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.46359\n",
      "Epoch 31/500\n",
      "134/134 [==============================] - 97s 721ms/step - loss: 1.3258 - acc: 0.6025 - val_loss: 1.4168 - val_acc: 0.5929\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.46359 to 1.41680, saving model to best_9.h5\n",
      "Epoch 32/500\n",
      "134/134 [==============================] - 96s 717ms/step - loss: 1.2973 - acc: 0.6143 - val_loss: 1.4504 - val_acc: 0.5855\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.41680\n",
      "Epoch 33/500\n",
      "134/134 [==============================] - 99s 740ms/step - loss: 1.2822 - acc: 0.6199 - val_loss: 1.4459 - val_acc: 0.5897\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.41680\n",
      "Epoch 34/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.2896 - acc: 0.6120 - val_loss: 1.4436 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.41680\n",
      "Epoch 35/500\n",
      "134/134 [==============================] - 92s 687ms/step - loss: 1.2824 - acc: 0.6123 - val_loss: 1.4510 - val_acc: 0.5962\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.41680\n",
      "Epoch 36/500\n",
      "134/134 [==============================] - 93s 692ms/step - loss: 1.2594 - acc: 0.6188 - val_loss: 1.4076 - val_acc: 0.6090\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.41680 to 1.40763, saving model to best_9.h5\n",
      "Epoch 37/500\n",
      "134/134 [==============================] - 92s 686ms/step - loss: 1.2405 - acc: 0.6227 - val_loss: 1.4317 - val_acc: 0.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_loss did not improve from 1.40763\n",
      "Epoch 38/500\n",
      "134/134 [==============================] - 92s 688ms/step - loss: 1.2049 - acc: 0.6340 - val_loss: 1.3817 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.40763 to 1.38170, saving model to best_9.h5\n",
      "Epoch 39/500\n",
      "134/134 [==============================] - 91s 682ms/step - loss: 1.2205 - acc: 0.6305 - val_loss: 1.3251 - val_acc: 0.6335\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.38170 to 1.32508, saving model to best_9.h5\n",
      "Epoch 40/500\n",
      "134/134 [==============================] - 92s 688ms/step - loss: 1.1862 - acc: 0.6451 - val_loss: 1.4152 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.32508\n",
      "Epoch 41/500\n",
      "134/134 [==============================] - 91s 676ms/step - loss: 1.1711 - acc: 0.6452 - val_loss: 1.4080 - val_acc: 0.6111\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.32508\n",
      "Epoch 42/500\n",
      "134/134 [==============================] - 92s 689ms/step - loss: 1.1827 - acc: 0.6406 - val_loss: 1.3576 - val_acc: 0.6154\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.32508\n",
      "Epoch 43/500\n",
      "134/134 [==============================] - 93s 694ms/step - loss: 1.1375 - acc: 0.6543 - val_loss: 1.3983 - val_acc: 0.6175\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.32508\n",
      "Epoch 44/500\n",
      "134/134 [==============================] - 93s 696ms/step - loss: 1.1548 - acc: 0.6554 - val_loss: 1.3838 - val_acc: 0.6218\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.32508\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 45/500\n",
      "134/134 [==============================] - 93s 697ms/step - loss: 1.0836 - acc: 0.6705 - val_loss: 1.3531 - val_acc: 0.6239\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.32508\n",
      "Epoch 46/500\n",
      "134/134 [==============================] - 91s 681ms/step - loss: 1.0579 - acc: 0.6752 - val_loss: 1.3445 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.32508\n",
      "Epoch 47/500\n",
      "134/134 [==============================] - 92s 687ms/step - loss: 1.0777 - acc: 0.6721 - val_loss: 1.3192 - val_acc: 0.6325\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.32508 to 1.31916, saving model to best_9.h5\n",
      "Epoch 48/500\n",
      "134/134 [==============================] - 93s 691ms/step - loss: 1.0682 - acc: 0.6782 - val_loss: 1.4079 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.31916\n",
      "Epoch 49/500\n",
      "134/134 [==============================] - 93s 691ms/step - loss: 1.0284 - acc: 0.6830 - val_loss: 1.3328 - val_acc: 0.6357\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.31916\n",
      "Epoch 50/500\n",
      "134/134 [==============================] - 91s 681ms/step - loss: 1.0411 - acc: 0.6791 - val_loss: 1.3650 - val_acc: 0.6368\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.31916\n",
      "Epoch 51/500\n",
      "134/134 [==============================] - 92s 690ms/step - loss: 1.0463 - acc: 0.6805 - val_loss: 1.4214 - val_acc: 0.6090\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.31916\n",
      "Epoch 52/500\n",
      "134/134 [==============================] - 92s 689ms/step - loss: 1.0197 - acc: 0.6907 - val_loss: 1.4384 - val_acc: 0.6079\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.31916\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 53/500\n",
      "134/134 [==============================] - 92s 689ms/step - loss: 0.9759 - acc: 0.7029 - val_loss: 1.3398 - val_acc: 0.6271\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.31916\n",
      "Epoch 54/500\n",
      "134/134 [==============================] - 95s 713ms/step - loss: 0.9645 - acc: 0.7054 - val_loss: 1.2866 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.31916 to 1.28657, saving model to best_9.h5\n",
      "Epoch 55/500\n",
      "134/134 [==============================] - 92s 687ms/step - loss: 0.9535 - acc: 0.7054 - val_loss: 1.4621 - val_acc: 0.6079\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.28657\n",
      "Epoch 56/500\n",
      "134/134 [==============================] - 94s 704ms/step - loss: 0.9492 - acc: 0.7106 - val_loss: 1.3166 - val_acc: 0.6271\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.28657\n",
      "Epoch 57/500\n",
      "134/134 [==============================] - 93s 692ms/step - loss: 0.9524 - acc: 0.7099 - val_loss: 1.3228 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.28657\n",
      "Epoch 58/500\n",
      "134/134 [==============================] - 93s 690ms/step - loss: 0.9489 - acc: 0.7121 - val_loss: 1.3566 - val_acc: 0.6261\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.28657\n",
      "Epoch 59/500\n",
      "134/134 [==============================] - 95s 711ms/step - loss: 0.9548 - acc: 0.7105 - val_loss: 1.3944 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.28657\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 60/500\n",
      "134/134 [==============================] - 94s 700ms/step - loss: 0.8920 - acc: 0.7223 - val_loss: 1.3336 - val_acc: 0.6528\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.28657\n",
      "Epoch 61/500\n",
      "134/134 [==============================] - 95s 709ms/step - loss: 0.8990 - acc: 0.7243 - val_loss: 1.3336 - val_acc: 0.6378\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.28657\n",
      "Epoch 62/500\n",
      "134/134 [==============================] - 94s 700ms/step - loss: 0.8859 - acc: 0.7313 - val_loss: 1.3314 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.28657\n"
     ]
    }
   ],
   "source": [
    "PREDICTION_FOLDER = \"./predictions_1d_conv/\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds,\n",
    "                      shuffle=True, random_state=13)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    train_set = train.iloc[train_split]\n",
    "    val_set = train.iloc[val_split]\n",
    "    checkpoint = ModelCheckpoint('../model/best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                save_weights_only=False)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=8)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "    rLR = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, verbose=1, mode='min')\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb, rLR]\n",
    "    print(\"Fold: \", i)\n",
    "    print(\"#\"*50)\n",
    "\n",
    "    model = get_1d_conv_model(config)\n",
    "\n",
    "\n",
    "    train_generator = DataGenerator(config, '../data/audio_train/', train_set.index, \n",
    "                                    train_set.label_idx, batch_size=64,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    val_generator = DataGenerator(config, '../data/audio_train/', val_set.index, \n",
    "                                  val_set.label_idx, batch_size=64,\n",
    "                                  preprocessing_fn=audio_norm)\n",
    "\n",
    "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                  epochs=500, use_multiprocessing=True, workers=6, max_queue_size=40)\n",
    "\n",
    "#     model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "#     # Save train predictions\n",
    "#     train_generator = DataGenerator(config, './dataset/audio_train/', train.index, batch_size=128,\n",
    "#                                     preprocessing_fn=audio_norm)\n",
    "#     predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "#                                           workers=6, max_queue_size=40, verbose=1)\n",
    "#     np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "#     # Save test predictions\n",
    "#     test_generator = DataGenerator(config, './dataset/audio_test/', test.index, batch_size=128,\n",
    "#                                     preprocessing_fn=audio_norm)\n",
    "#     predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "#                                           workers=6, max_queue_size=40, verbose=1)\n",
    "#     np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "#     # Make a submission file\n",
    "#     top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "#     predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "#     test['label'] = predicted_labels\n",
    "#     test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "# for i in range(10):\n",
    "#     pred_list.append(np.load(PREDICTION_FOLDER +\"/test_predictions_%d.npy\"%i))\n",
    "# prediction = np.ones_like(pred_list[0])\n",
    "# for pred in pred_list:\n",
    "#     prediction = prediction*pred\n",
    "# prediction = prediction**(1./len(pred_list))\n",
    "# # Make a submission file\n",
    "# top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "# predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "# test = pd.read_csv('./dataset/sample_submission.csv')\n",
    "# test['label'] = predicted_labels\n",
    "# test[['fname', 'label']].to_csv(\"1d_conv_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
